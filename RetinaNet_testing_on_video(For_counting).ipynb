{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RetinaNet-testing-on-video(For counting).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mr7495/Sperm_detection_and_tracking/blob/master/RetinaNet_testing_on_video(For_counting).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdEVKxopmz44"
      },
      "source": [
        "!pip uninstall keras\r\n",
        "!pip uninstall tensorflow\r\n",
        "!pip install tensorflow==1.15\r\n",
        "!pip install keras==2.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fTRjNXa0vGg"
      },
      "source": [
        "!nvidia-smi #show GPU if one is enabled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAgWM1SawpDO"
      },
      "source": [
        "!pip install git+https://github.com/mr7495/RetinaNet_Motile_objects_Detection --upgrade #Install RetinaNet as a library"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqz4jiezix-r"
      },
      "source": [
        "!git clone https://github.com/mr7495/RetinaNet_Motile_objects_Detection #Clone the data on colab runtime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJBr_oHfj2Ax"
      },
      "source": [
        "cd RetinaNet_Motile_objects_Detection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa-TRlxPi-Al"
      },
      "source": [
        "!python setup.py build_ext --inplace"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq8dIaKpNXZu"
      },
      "source": [
        "cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-mZGiy7Gy_g"
      },
      "source": [
        "# show images inline\n",
        "%matplotlib inline\n",
        "\n",
        "# automatically reload modules when they have changed\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# import keras\n",
        "import keras\n",
        "import csv\n",
        "# import keras_retinanet\n",
        "from keras_retinanet import models\n",
        "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
        "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
        "from keras_retinanet.utils.colors import label_color\n",
        "\n",
        "# import miscellaneous modules\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "from google.colab.patches import cv2_imshow\n",
        "# set tf backend to allow memory to grow, instead of claiming everything\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dIKVuaCuTab"
      },
      "source": [
        "#Our trained RetinaNet for detecting sperms based on 3 consecutive frames is free to use on:\n",
        "#https://drive.google.com/open?id=1pN3A-tWJOphRdTZ7cPhJTnTIhoiGrcWv\n",
        "#Add this file to your drive and connbet you google drive to colab using:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GIyy7jWHDin"
      },
      "source": [
        "model_path = 'drive/MyDrive/final_retinanet_sperm_detection_3frames.h5' #Path to inference model\n",
        "\n",
        "# load retinanet model\n",
        "\n",
        "model = models.load_model(model_path)\n",
        "#print(model.summary())\n",
        "\n",
        "# load label to names mapping for visualization purposes\n",
        "labels_to_names = {0: 'Sperm'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gCkJC7Oi13h"
      },
      "source": [
        "# In this block you will import the address of your video\r\n",
        "video_file='RetinaNet_Motile_objects_Detection/13910927_4.avi' #path to the video file\r\n",
        "save_path='frames' #path to the folder to save video\r\n",
        "video_data=[]\r\n",
        "cap = cv2.VideoCapture(video_file) #read video\r\n",
        "count = 0\r\n",
        "import shutil\r\n",
        "try:\r\n",
        "  shutil.rmtree(save_path)\r\n",
        "except:\r\n",
        "  pass\r\n",
        "#create folder\r\n",
        "try:\r\n",
        "    os.mkdir(save_path)\r\n",
        "except:\r\n",
        "    pass\r\n",
        "while cap.isOpened():\r\n",
        "    ret,frame = cap.read()\r\n",
        "    if ret is True:     \r\n",
        "        count = count + 1\r\n",
        "        cv2.imwrite(\"{}/{}.jpg\".format(save_path,count), frame) #write frame\r\n",
        "        video_data.append(\"{}/{}.jpg\".format(save_path,count))  #add the data to the list\r\n",
        "    else:\r\n",
        "        break\r\n",
        "cap.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k2O4PAd1-KL"
      },
      "source": [
        "data=[]\n",
        "for index,frame_data in enumerate(video_data):\n",
        "  if index==0: #first frame\n",
        "    img1 = read_image_bgr(frame_data) #Load Previous Frame\n",
        "    img2 = read_image_bgr(frame_data) #Load Current Frame\n",
        "    img3 = read_image_bgr(video_data[index+1]) #Load next Frame\n",
        "  elif index== len(video_data)-1: #last frame\n",
        "    img1 = read_image_bgr(video_data[index-1]) #Load Previous Frame\n",
        "    img2 = read_image_bgr(frame_data) #Load Current Frame\n",
        "    img3 = read_image_bgr(frame_data) #Load next Frame\n",
        "  else: #other frames\n",
        "    img1 = read_image_bgr(video_data[index-1]) #Load Previous Frame\n",
        "    img2 = read_image_bgr(frame_data) #Load Current Frame\n",
        "    img3 = read_image_bgr(video_data[index+1]) #Load next Frame\n",
        "\n",
        "  img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY) #convert to gray scale\n",
        "  img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY) #convert to gray scale\n",
        "  img3 = cv2.cvtColor(img3, cv2.COLOR_BGR2GRAY) #convert to gray scale\n",
        "  image=np.concatenate((np.expand_dims(img1,axis=2),np.expand_dims(img2,axis=2),np.expand_dims(img3,axis=2)),axis=2) #concatenate 3 consecutive frames\n",
        "\n",
        "  draw = read_image_bgr(frame_data) #the original current frame image\n",
        "\n",
        "  # preprocess image for network\n",
        "  image = preprocess_image(image)\n",
        "  image, scale = resize_image(image)\n",
        "\n",
        "  # process image\n",
        "  start = time.time()\n",
        "  boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
        "  print(\"processing time: \", time.time() - start)\n",
        "\n",
        "  # correct for image scale\n",
        "  boxes /= scale\n",
        "\n",
        "\n",
        "  # visualize detections\n",
        "  for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
        "      # scores are sorted so we can break\n",
        "      if score<0.5:\n",
        "        break\n",
        "  \n",
        "      color = (255,0,0)\n",
        "      \n",
        "      b = box.astype(int)\n",
        "      draw_box(draw, b, color=color)\n",
        "      \n",
        "      caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
        "      draw_caption(draw, b, caption)\n",
        "      data.append([frame_data,b[0],b[1],b[2],b[3],'sperm']) #add the data to the list\n",
        "\n",
        "  cv2_imshow(draw)\n",
        "  cv2.imwrite('detected.jpg',draw)\n",
        "\n",
        "with open('detections.csv','w',newline='') as f: #write the data to a csv file which will be used for tracking\n",
        "  csvwriter=csv.writer(f)\n",
        "  for row in data:\n",
        "    csvwriter.writerow(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDdgQWRJppET"
      },
      "source": [
        "#Download detections.csv and use it for perform tracking (via modified csr-dcf.py file)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}